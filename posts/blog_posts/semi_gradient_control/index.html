<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Semi-Gradient Control Methods | Bedir Tapkan</title><meta name=keywords content="Reinforcement Learning,Control,SARSA,BetterRL"><meta name=description content="Prime numbers are really important, how do we find them though?"><meta name=author content="Bedir Tapkan"><link rel=canonical href=https://bedirtapkan.com/posts/blog_posts/semi_gradient_control/><link crossorigin=anonymous href=/assets/css/stylesheet.min.8e91082900dbf810230d49642f818a9195d16c689d1637a6f8505e559c4b1d25.css integrity="sha256-jpEIKQDb+BAjDUlkL4GKkZXRbGidFjem+FBeVZxLHSU=" rel="preload stylesheet" as=style><link rel=icon href=https://bedirtapkan.com/favicon.ico><link rel=apple-touch-icon href=https://bedirtapkan.com/apple-touch-icon.png><meta name=twitter:title content="Semi-Gradient Control Methods | Bedir Tapkan"><meta name=twitter:description content="Prime numbers are really important, how do we find them though?"><meta property="og:title" content="Semi-Gradient Control Methods | Bedir Tapkan"><meta property="og:description" content="Prime numbers are really important, how do we find them though?"><meta property="og:type" content="article"><meta property="og:url" content="https://bedirtapkan.com/posts/blog_posts/semi_gradient_control/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-03-10T00:00:00+00:00"><meta property="article:modified_time" content="2020-03-10T00:00:00+00:00"><meta property="og:site_name" content="Bedir Tapkan"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bedirtapkan.com/posts/"},{"@type":"ListItem","position":3,"name":"Semi-Gradient Control Methods","item":"https://bedirtapkan.com/posts/blog_posts/semi_gradient_control/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Semi-Gradient Control Methods | Bedir Tapkan","name":"Semi-Gradient Control Methods","description":"Prime numbers are really important, how do we find them though?","keywords":["Reinforcement Learning","Control","SARSA","BetterRL"],"wordCount":"1733","inLanguage":"en","datePublished":"2020-03-10T00:00:00Z","dateModified":"2020-03-10T00:00:00Z","author":{"@type":"Person","name":"Bedir Tapkan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bedirtapkan.com/posts/blog_posts/semi_gradient_control/"},"publisher":{"@type":"Organization","name":"Bedir Tapkan","logo":{"@type":"ImageObject","url":"https://bedirtapkan.com/favicon.ico"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary-bg:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list-page{background:var(--theme)}.list-page:not(.dark)::-webkit-scrollbar-track{background:0 0}.list-page:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body class="type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="auto",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><header class=header><nav class=nav><div class=logo><a href=https://bedirtapkan.com accesskey=h title="Bedir Tapkan (Alt + H)">Bedir Tapkan</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://bedirtapkan.com/about/ title=About>About</a></li><li><a href=https://bedirtapkan.com/projects/ title=Projects>Projects</a></li><li><a href=https://bedirtapkan.com/archives/ title=Archives>Archives</a></li><li><a href=https://bedirtapkan.com/search/ title="Search (Alt + /)" data-no-instant accesskey=/>Search</a></li><li><a href=https://bedirtapkan.com/design/ title="3D Projects">3D Projects</a></li></ul></nav></header><main class="main post"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bedirtapkan.com>Home</a>&nbsp;»&nbsp;<a href=https://bedirtapkan.com/posts/>Posts</a></div><h1 class=post-title>Semi-Gradient Control Methods</h1><div class=post-description>Prime numbers are really important, how do we find them though?</div><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>March 10, 2020</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=https://bedirtapkan.com/tags/reinforcement-learning/>Reinforcement Learning</a><a href=https://bedirtapkan.com/tags/control/>Control</a><a href=https://bedirtapkan.com/tags/sarsa/>SARSA</a><a href=https://bedirtapkan.com/tags/betterrl/>BetterRL</a></span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg>
<span>1733 words</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>9 min</span></span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#implementation>Implementation</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h3 id=prerequisites>Prerequisites<a hidden class=anchor aria-hidden=true href=#prerequisites>¶</a></h3><ul><li>Semi-Gradient Prediction</li><li>Intro to Linear Methods</li></ul><p>If you read the prediction part for the semi gradient methods, it is pretty easy to extend what we know to the control case. We know that control is almost all the time just adding policy improvement over the prediction case. That&rsquo;s exactly the case for us here for semi-gradient control methods as well.</p><p>We already have describe and understood a formula back in prediction part (if you read it somewhere else that&rsquo;s also fine), and now we want to extend our window a little.</p><p>For prediction we were using $S_t \mapsto U_t$ examples, now since we have action-values instead of state-values (because we will pick the best action possible), we will use examples of form $S_t, A_t \mapsto U_t$ meaning that instead of $v_\pi(S_t)$ we will be using estimations for $q_\pi(S_t, A_t)$.</p><p>So our general update rule would be (following from the formula for prediction);</p><p>$$
w_{t+1} = w_t + \alpha [U_t - \hat{q}(S_t, A_t, w_t)] \nabla\hat{q}(S_t, A_t, w_t)
$$</p><p>As we always do, you can replace $U_t$ with any approximation method you want, so it could have been a Monte Carlo method (Though I believe this does not count as semi-gradient, because it will be a direct stochastic gradient since it does not use any bootstrapping, but the book says otherwise so I am just passing the information 😄). Therefor we can implement an $n$-step episodic SARSA with an infinite option, which will correspond to Monte-Carlo (We will learn a better method to do this in future posts).</p><p>The last piece of information to add is the policy improvement part, since we are doing control, we need to update our policy and make it better as we go of course. Which won&rsquo;t be hard cause we will just be using a soft approximation method, I will use the classic $\epsilon$-greedy policy.</p><p>One more thing to note, which I think is pretty important, for continuous action spaces, or large discrete action spaces methods for the control part is still not clear. Meaning we don&rsquo;t know what is the best way to approach yet. That is if you think of a large choices of actions, there is no good way to apply a soft approximation technique for the action selection as you can imagine.</p><p>For the implementation, as usual we will just go linear, as it is the best way to grasp every piece of information. But first I will as usual give the pseudo-code given in the book.</p><p><img loading=lazy src=/posts/blog_posts/semi_gradient_control/images/sg_sarsa.png type alt></p><p>I only took the pseudocode from chapter 10.2 because we don&rsquo;t really the one before, as it is only the one step version. We are interested in the general version therefor n-step.</p><h3 id=implementation>Implementation<a hidden class=anchor aria-hidden=true href=#implementation>¶</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-1> 1</a>
</span><span class=lnt id=hl-0-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-2> 2</a>
</span><span class=lnt id=hl-0-3><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-3> 3</a>
</span><span class=lnt id=hl-0-4><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-4> 4</a>
</span><span class=lnt id=hl-0-5><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-5> 5</a>
</span><span class=lnt id=hl-0-6><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-6> 6</a>
</span><span class=lnt id=hl-0-7><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-7> 7</a>
</span><span class=lnt id=hl-0-8><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-8> 8</a>
</span><span class=lnt id=hl-0-9><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-9> 9</a>
</span><span class=lnt id=hl-0-10><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-10>10</a>
</span><span class=lnt id=hl-0-11><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-11>11</a>
</span><span class=lnt id=hl-0-12><a style=outline:none;text-decoration:none;color:inherit href=#hl-0-12>12</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>feature_space</span><span class=p>,</span> <span class=n>action_space</span><span class=p>,</span> <span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.0001</span><span class=p>,</span> <span class=n>gamma</span> <span class=o>=</span> <span class=mf>0.99</span><span class=p>,</span> <span class=n>eps</span> <span class=o>=</span> <span class=mf>.1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>=</span> <span class=n>alpha</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>gamma</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>=</span> <span class=n>eps</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>feature_space</span> <span class=o>=</span> <span class=n>feature_space</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>action_space</span> <span class=o>=</span> <span class=n>action_space</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>reset_weights</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>reset_weights</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>w</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>feature_space</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>action_space</span><span class=p>)</span>        
</span></span></code></pre></td></tr></table></div></div><p><strong>Initialize</strong> We start by initializing the necessary things; we need step size $\alpha$ also $\gamma$ and $\epsilon$. Other then these we need to initialize our weight vector. We will have a weight vector that is for each action concatenated after one another. So if we assume that we have 4 observations lets say [1 0 1 0], meaning weights 0 and 2 are active, and if want to update the weights for action 0, we will have [<strong>1 0 1 0</strong> 0 0 0 0 0 0 0 0] if we had 3 possible actions in total. After when we are using $\epsilon$-greedy this will make more sense.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-1-1>1</a>
</span><span class=lnt id=hl-1-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-1-2>2</a>
</span><span class=lnt id=hl-1-3><a style=outline:none;text-decoration:none;color:inherit href=#hl-1-3>3</a>
</span><span class=lnt id=hl-1-4><a style=outline:none;text-decoration:none;color:inherit href=#hl-1-4>4</a>
</span><span class=lnt id=hl-1-5><a style=outline:none;text-decoration:none;color:inherit href=#hl-1-5>5</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>obs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>sample</span><span class=p>()</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>eps</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_act</span><span class=p>(</span><span class=n>obs</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>action_space</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>Let&rsquo;s move</strong> next thing is to take a step, meaning we will pick the action according to our action-values at hand. We take the observations as input, this will come from the environment, and assuming we get an array of the probabilities for each action given the observations from <code>_act(obs)</code>. Then all we have to do is to roll the die and decide if we will choose a random action or we will choose the action that has the most value for the current time, and thats exactly what we do here ($\epsilon$-greedy action selection).</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-2-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-2-1>1</a>
</span><span class=lnt id=hl-2-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-2-2>2</a>
</span><span class=lnt id=hl-2-3><a style=outline:none;text-decoration:none;color:inherit href=#hl-2-3>3</a>
</span><span class=lnt id=hl-2-4><a style=outline:none;text-decoration:none;color:inherit href=#hl-2-4>4</a>
</span><span class=lnt id=hl-2-5><a style=outline:none;text-decoration:none;color:inherit href=#hl-2-5>5</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_act</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>obs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>q_vals</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>action_space</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>action_space</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>q_vals</span><span class=p>[</span><span class=n>a</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>q_hat</span><span class=p>(</span><span class=n>obs</span><span class=p>,</span> <span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>q_vals</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>Best $\hat{q}$-value</strong> now we need to fill the function <code>_act(obs)</code>. Which basically will call $\hat{q}(s, a, w)$ for each action and store them in an array and return it.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-3-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-3-1>1</a>
</span><span class=lnt id=hl-3-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-3-2>2</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>q_hat</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>obs</span><span class=p>,</span> <span class=n>action</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>w</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_x</span><span class=p>(</span><span class=n>obs</span><span class=p>,</span> <span class=n>action</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Continuing from there we have the $\hat{q}(s,a,w)$ to implement. Which is just writing down the linear formula since we are implementing it linearly. Therefor $\hat{q}(s,a,w) = w^Tx(s, a)$ where $x(s,a)$ is the state action representation. In our case as I already mention this will just be the one hot vector, all the observations are added after one another for each action.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-4-1>1</a>
</span><span class=lnt id=hl-4-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-4-2>2</a>
</span><span class=lnt id=hl-4-3><a style=outline:none;text-decoration:none;color:inherit href=#hl-4-3>3</a>
</span><span class=lnt id=hl-4-4><a style=outline:none;text-decoration:none;color:inherit href=#hl-4-4>4</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_x</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>obs</span><span class=p>,</span> <span class=n>action</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>one_hot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>one_hot</span><span class=p>[</span><span class=n>action</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>feature_space</span><span class=p>:(</span><span class=n>action</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>feature_space</span><span class=p>]</span> <span class=o>=</span> <span class=n>obs</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>one_hot</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>Finally</strong> $x(s, a)$ - as I already mentioned twice 😄 we create the $x$ in a vector that everything 0 other than the active action.</p><p>That was the last thing for us to be able to choose the action for a given state. So let&rsquo;s have a broader respective and assume that we are using the <code>step(obs)</code> here is how it would be like:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-5-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-5-1>1</a>
</span><span class=lnt id=hl-5-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-5-2>2</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>action</span> <span class=o>=</span> <span class=n>agent</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>obs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>obs</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Now we see what is left ? Update&mldr; 🤦‍♂️ Yeah without update there is no change basically. Which will also be the one differs for the $n$. Let&rsquo;s remember the formula;</p><p>$$
w_{t+1} = w_t + \alpha[R_{t+1} + \gamma R_{t+2} + \ldots + \gamma^n\hat{q}(S_{t+n},A_{t+n},w_{t}) - \hat{q}(S_{t},A_{t},w_{t})] \nabla\hat{q}(S_t, A_t, w_t)
$$</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-6-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-1> 1</a>
</span><span class=lnt id=hl-6-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-2> 2</a>
</span><span class=lnt id=hl-6-3><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-3> 3</a>
</span><span class=lnt id=hl-6-4><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-4> 4</a>
</span><span class=lnt id=hl-6-5><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-5> 5</a>
</span><span class=lnt id=hl-6-6><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-6> 6</a>
</span><span class=lnt id=hl-6-7><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-7> 7</a>
</span><span class=lnt id=hl-6-8><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-8> 8</a>
</span><span class=lnt id=hl-6-9><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-9> 9</a>
</span><span class=lnt id=hl-6-10><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-10>10</a>
</span><span class=lnt id=hl-6-11><a style=outline:none;text-decoration:none;color:inherit href=#hl-6-11>11</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>update</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>observations</span><span class=p>,</span> <span class=n>actions</span><span class=p>,</span> <span class=n>rewards</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>observations</span><span class=p>)</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>observations</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>rewards</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>actions</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>rewards</span><span class=p>)</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>G</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>([(</span><span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>**</span> <span class=n>t</span><span class=p>)</span> <span class=o>*</span> <span class=n>r</span> <span class=k>for</span> <span class=n>t</span><span class=p>,</span><span class=n>r</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>rewards</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>])])</span>
</span></span><span class=line><span class=cl>            <span class=n>G</span> <span class=o>+=</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>**</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n</span><span class=p>))</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>_q_hat</span><span class=p>(</span><span class=n>observations</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=n>actions</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>w</span> <span class=o>+=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=p>(</span><span class=n>G</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>_q_hat</span><span class=p>(</span><span class=n>observations</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>actions</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span> <span class=o>*</span> \
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_grad_q_hat</span><span class=p>(</span><span class=n>observations</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>actions</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>There is a bit of a change here, from the pseudocode I provided. Since we want a full seperation between the agent-environment-experiment we need a class system for the algorithms therefor we won&rsquo;t be following what is on the pseudocode.</p><p><strong>Update</strong> what happens here is actually not that different, since we only need $n+1$ elements to make the update happen we won&rsquo;t keep the rest of the trajectory. Whenever we use n numbered trajectory the first element becomes useless for the next update. Therefor we remove the first element from the trajectory and use the rest to make our update.</p><p><strong>Terminal</strong> we also have a terminal state, and as can be seen in the pseudocode there are some differences that should be changed for the updates when we reach the terminal state. Logical enough, we do not have n+1 element left to complete the calculation we were doing therefor we will just use the rewards rather than $\hat{q}(s,a,w)$ . Therefor we need another function to handle this, which we call <code>end()</code> in our structure;</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-7-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-1>1</a>
</span><span class=lnt id=hl-7-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-2>2</a>
</span><span class=lnt id=hl-7-3><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-3>3</a>
</span><span class=lnt id=hl-7-4><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-4>4</a>
</span><span class=lnt id=hl-7-5><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-5>5</a>
</span><span class=lnt id=hl-7-6><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-6>6</a>
</span><span class=lnt id=hl-7-7><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-7>7</a>
</span><span class=lnt id=hl-7-8><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-8>8</a>
</span><span class=lnt id=hl-7-9><a style=outline:none;text-decoration:none;color:inherit href=#hl-7-9>9</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>end</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>observations</span><span class=p>,</span> <span class=n>actions</span><span class=p>,</span> <span class=n>rewards</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>observations</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>rewards</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>actions</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>G</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>([(</span><span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>**</span> <span class=n>t</span><span class=p>)</span> <span class=o>*</span> <span class=n>r</span> <span class=k>for</span> <span class=n>t</span><span class=p>,</span><span class=n>r</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>rewards</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>w</span> <span class=o>+=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=p>(</span><span class=n>G</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>_q_hat</span><span class=p>(</span><span class=n>observations</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>actions</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span> <span class=o>*</span> \
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_grad_q_hat</span><span class=p>(</span><span class=n>observations</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>actions</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Here as we can see we are not doing something too different. It is just that we are using the last elements we have left and we will remove all the elements from the trajectory while making the last updates to our weights.</p><p>Yeah and we are almost done, exept that I didn&rsquo;t show the <code>grad_q_hat()</code> yet, which basically gives the $\nabla\hat{q}(s,a,w)$.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-8-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-8-1>1</a>
</span><span class=lnt id=hl-8-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-8-2>2</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>grad_q_hat</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>obs</span><span class=p>,</span> <span class=n>action</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_x</span><span class=p>(</span><span class=n>obs</span><span class=p>,</span> <span class=n>action</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Surprise.. Yeah since we are using linear functions, $\nabla w^Tx(s, a) = x(s,a)$. That&rsquo;s all.</p><p>Let&rsquo;s see how would be the experiment part and run the code to get some results then.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-9-1><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-1> 1</a>
</span><span class=lnt id=hl-9-2><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-2> 2</a>
</span><span class=lnt id=hl-9-3><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-3> 3</a>
</span><span class=lnt id=hl-9-4><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-4> 4</a>
</span><span class=lnt id=hl-9-5><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-5> 5</a>
</span><span class=lnt id=hl-9-6><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-6> 6</a>
</span><span class=lnt id=hl-9-7><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-7> 7</a>
</span><span class=lnt id=hl-9-8><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-8> 8</a>
</span><span class=lnt id=hl-9-9><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-9> 9</a>
</span><span class=lnt id=hl-9-10><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-10>10</a>
</span><span class=lnt id=hl-9-11><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-11>11</a>
</span><span class=lnt id=hl-9-12><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-12>12</a>
</span><span class=lnt id=hl-9-13><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-13>13</a>
</span><span class=lnt id=hl-9-14><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-14>14</a>
</span><span class=lnt id=hl-9-15><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-15>15</a>
</span><span class=lnt id=hl-9-16><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-16>16</a>
</span><span class=lnt id=hl-9-17><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-17>17</a>
</span><span class=lnt id=hl-9-18><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-18>18</a>
</span><span class=lnt id=hl-9-19><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-19>19</a>
</span><span class=lnt id=hl-9-20><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-20>20</a>
</span><span class=lnt id=hl-9-21><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-21>21</a>
</span><span class=lnt id=hl-9-22><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-22>22</a>
</span><span class=lnt id=hl-9-23><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-23>23</a>
</span><span class=lnt id=hl-9-24><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-24>24</a>
</span><span class=lnt id=hl-9-25><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-25>25</a>
</span><span class=lnt id=hl-9-26><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-26>26</a>
</span><span class=lnt id=hl-9-27><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-27>27</a>
</span><span class=lnt id=hl-9-28><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-28>28</a>
</span><span class=lnt id=hl-9-29><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-29>29</a>
</span><span class=lnt id=hl-9-30><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-30>30</a>
</span><span class=lnt id=hl-9-31><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-31>31</a>
</span><span class=lnt id=hl-9-32><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-32>32</a>
</span><span class=lnt id=hl-9-33><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-33>33</a>
</span><span class=lnt id=hl-9-34><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-34>34</a>
</span><span class=lnt id=hl-9-35><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-35>35</a>
</span><span class=lnt id=hl-9-36><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-36>36</a>
</span><span class=lnt id=hl-9-37><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-37>37</a>
</span><span class=lnt id=hl-9-38><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-38>38</a>
</span><span class=lnt id=hl-9-39><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-39>39</a>
</span><span class=lnt id=hl-9-40><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-40>40</a>
</span><span class=lnt id=hl-9-41><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-41>41</a>
</span><span class=lnt id=hl-9-42><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-42>42</a>
</span><span class=lnt id=hl-9-43><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-43>43</a>
</span><span class=lnt id=hl-9-44><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-44>44</a>
</span><span class=lnt id=hl-9-45><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-45>45</a>
</span><span class=lnt id=hl-9-46><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-46>46</a>
</span><span class=lnt id=hl-9-47><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-47>47</a>
</span><span class=lnt id=hl-9-48><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-48>48</a>
</span><span class=lnt id=hl-9-49><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-49>49</a>
</span><span class=lnt id=hl-9-50><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-50>50</a>
</span><span class=lnt id=hl-9-51><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-51>51</a>
</span><span class=lnt id=hl-9-52><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-52>52</a>
</span><span class=lnt id=hl-9-53><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-53>53</a>
</span><span class=lnt id=hl-9-54><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-54>54</a>
</span><span class=lnt id=hl-9-55><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-55>55</a>
</span><span class=lnt id=hl-9-56><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-56>56</a>
</span><span class=lnt id=hl-9-57><a style=outline:none;text-decoration:none;color:inherit href=#hl-9-57>57</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;num_of_episodes&#39;</span> <span class=p>:</span> <span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;max_steps&#39;</span> <span class=p>:</span> <span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;alpha&#39;</span> <span class=p>:</span> <span class=mi>2</span> <span class=o>**</span> <span class=p>(</span><span class=o>-</span><span class=mi>14</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;gamma&#39;</span> <span class=p>:</span> <span class=mf>0.98</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># Creating the tilings</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;grid_size&#39;</span> <span class=p>:</span> <span class=mi>5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;tile_size&#39;</span> <span class=p>:</span> <span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;num_of_tiles&#39;</span> <span class=p>:</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=c1># environment</span>
</span></span><span class=line><span class=cl><span class=n>env</span> <span class=o>=</span> <span class=n>grid_world</span><span class=p>(</span><span class=n>portal</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>action_space</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>action_space</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># tile coding</span>
</span></span><span class=line><span class=cl><span class=n>tilings</span> <span class=o>=</span> <span class=n>tile_coding</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>grid_size</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>params</span><span class=p>[</span><span class=s1>&#39;num_of_tiles&#39;</span><span class=p>],</span> <span class=n>params</span><span class=p>[</span><span class=s1>&#39;tile_size&#39;</span><span class=p>],</span> <span class=n>action_space</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>state_space</span> <span class=o>=</span> <span class=n>tilings</span><span class=o>.</span><span class=n>num_of_tilings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Keep stats for final print and data</span>
</span></span><span class=line><span class=cl><span class=n>episode_rewards</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;num_of_episodes&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Agent created</span>
</span></span><span class=line><span class=cl><span class=n>n</span> <span class=o>=</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl><span class=n>agent</span> <span class=o>=</span> <span class=n>SG_SARSA</span><span class=p>(</span><span class=n>state_space</span><span class=p>,</span> <span class=n>action_space</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>params</span><span class=p>[</span><span class=s1>&#39;alpha&#39;</span><span class=p>],</span> <span class=n>params</span><span class=p>[</span><span class=s1>&#39;gamma&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>ep</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;num_of_episodes&#39;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>rewards</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>observations</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>actions</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>obs</span> <span class=o>=</span> <span class=n>tilings</span><span class=o>.</span><span class=n>active_tiles</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>())</span> <span class=c1># a x d</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>score</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;max_steps&#39;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>action</span> <span class=o>=</span> <span class=n>agent</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>obs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>observations</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>obs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>obs</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>obs</span> <span class=o>=</span> <span class=n>tilings</span><span class=o>.</span><span class=n>active_tiles</span><span class=p>(</span><span class=n>obs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rewards</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>reward</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>actions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>+=</span> <span class=n>reward</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>done</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>agent</span><span class=o>.</span><span class=n>end</span><span class=p>(</span><span class=n>observations</span><span class=p>,</span> <span class=n>actions</span><span class=p>,</span> <span class=n>rewards</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>agent</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>observations</span><span class=p>,</span> <span class=n>actions</span><span class=p>,</span> <span class=n>rewards</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>		<span class=n>episode_rewards</span><span class=p>[</span><span class=n>ep</span><span class=p>]</span> <span class=o>=</span> <span class=n>score</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;EP: </span><span class=si>{}</span><span class=s2> -------- Return: </span><span class=si>{}</span><span class=s2>      &#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>ep</span><span class=p>,</span> <span class=n>score</span><span class=p>),</span> <span class=n>end</span><span class=o>=</span><span class=s2>&#34;</span><span class=se>\r</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>flush</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>I used tile coding and the grid world environment in our library. If you want you can modify a little to use another state representation or Rich Sutton&rsquo;s tile coding library, or for environment gym.</p><p>Anyways, what we do is pretty simple if you read through, and you can ask for clarification on any point if looks weird.</p><p>Main point here are the agent functions and how we use them, all three are used as we said, on each step we have the <code>agent.step()</code>, for each step we have the <code>update()</code> called except the terminal state. Which we will call <code>end()</code> instead.</p><p>I will give only one graph as result as usual, here is 100 runs on the stochastic grid world environment.</p><p><img loading=lazy src=/posts/blog_posts/semi_gradient_control/images/sg_sarsa_figure.jpg type alt></p><p>If you liked this post follow <a href=https://github.com/BedirT/BetterRL>BetterRL</a>, and keep a like down below. I have a blog series on RL algorithms that you can <a href=bedirt.github.io>check out</a>. Also you can check the repo where I share raw python RL code for both environments and algorithms. Any comments are appreciated!</p><p><a href=https://github.com/BedirT/BetterRL/blob/master/value_based/Semi_Gradient_SARSA.py>For full code</a></p></div><footer class=post-footer><nav class=paginav><a class=prev href=https://bedirtapkan.com/posts/blog_posts/average_reward/><span class=title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></svg>&nbsp;Prev Page</span><br><span>Average Reward, Continuing Tasks and Discounting</span></a>
<a class=next href=https://bedirtapkan.com/posts/blog_posts/counting_sort/><span class=title>Next Page&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg></span><br><span>Counting Sort</span></a></nav></footer></article></main><footer class=footer><span>© 2022</span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a></span>
<span style=display:inline-block;margin-left:1em>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n=""=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script>
<script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const a=""=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script></body></html>